{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4156be1b-f1ef-4ce3-b3d2-89bd54372409",
   "metadata": {},
   "source": [
    "# Prompt Engineering (on Llama-2-Chat model)\n",
    "\n",
    "Note demonstrates some prompting techniques and and how they can be used to get more desired answers which can be more accurate as well. It also demonstrates how we can get responses in a specific form so we can parse for further processing and use LLM as a part of bigger system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55eb1ae8-239a-4fe1-be8b-5b1056996af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775d8aac-37a8-4e41-9822-c403e4b8b9dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b683c0681c4f6f831c34a37b3d04c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    cache_dir=\"/data/yash/base_models\",\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", \n",
    "                                          cache_dir=\"/data/yash/base_models\"\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf361ef-b885-4bd9-a005-ea39630c8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_chat_reponse(prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature= 0.00001)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae059fd-4e60-4d50-bfa3-ad3e70882d1a",
   "metadata": {},
   "source": [
    "## Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db52a91-b904-4548-ad70-57b37e6cdac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST]\n",
      "Classify the text into neutral, negative or positive. \n",
      "Text: I just love it\n",
      "[/INST]\n",
      "Classification: Positive\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST]\n",
    "Classify the text into neutral, negative or positive. \n",
    "Text: I just love it\n",
    "[/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b3776d-edbd-4168-bed3-4d54711f78ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST]\n",
      "what is the hindi translation of the text \n",
      "Text: I like eating\n",
      "[/INST]\n",
      "The Hindi translation of the text \"I like eating\" is:\n",
      "\n",
      "à¤®à¥ˆà¤‚ à¤–à¤¾à¤¨à¤¾ à¤ªà¤¸à¤‚à¤¦ à¤•à¤°à¤¤à¤¾ à¤¹à¥‚à¤ (Main khana pasand karta hoon)\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST]\n",
    "what is the hindi translation of the text \n",
    "Text: I like eating\n",
    "[/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e0c59-023f-45ea-ad72-172b17a1dde4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cf35a89-2847-4180-9809-806cc291ffa0",
   "metadata": {},
   "source": [
    "## Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bdcf943-7edd-4588-82d1-e1cb64e9e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] To do a \"farduddle\" means to jump up and down really fast. An example of a sentence that uses\n",
      "the word farduddle is:  [/INST]\n",
      "I apologize, but \"farduddle\" is not a commonly recognized word in English. It is possible that it is a misspelling or a made-up word.\n",
      "\n",
      "If you meant to use the word \"fidget,\" which means to move your body around quickly and restlessly, you could use the sentence:\n",
      "\n",
      "\"She was fidgeting with excitement during the concert.\"\n",
      "\n",
      "Alternatively, if you meant to use a different word, please let me know and I'll be happy to help you with your sentence.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST] To do a \"farduddle\" means to jump up and down really fast. An example of a sentence that uses\n",
    "the word farduddle is:  [/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297f045c-5496-4cca-a517-3c53b408bd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] A \"whatpu\" is a small, furry animal native to Tanzania. An example of a sentence that uses\n",
      "the word whatpu is: [/INST]\n",
      "We were traveling in Africa and we saw these very cute whatpus.\n",
      "[INST] To do a \"farduddle\" means to jump up and down really fast. An example of a sentence that uses\n",
      "the word farduddle is: [/INST]\n",
      "The children were having a farduddle competition in the playground.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST] A \"whatpu\" is a small, furry animal native to Tanzania. An example of a sentence that uses\n",
    "the word whatpu is: [/INST]\n",
    "We were traveling in Africa and we saw these very cute whatpus.\n",
    "[INST] To do a \"farduddle\" means to jump up and down really fast. An example of a sentence that uses\n",
    "the word farduddle is: [/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdc798-4d8e-4dfd-b83b-7486f1dd518b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f8ce893-c924-43f2-a91d-96742ba65ebe",
   "metadata": {},
   "source": [
    "## Few Shot Prompting for Strcuture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bfcbb9d-f187-4f99-b745-223d974cf738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] <<SYS>>\n",
      "Classify the text into neutral, negative or positive.\n",
      "<</SYS>>\n",
      "\n",
      "I like this.[/INST]\n",
      "positive\n",
      "[INST] I hate this [/INST]\n",
      "negative\n",
      "[INST] this is ok [/INST]\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST] <<SYS>>\n",
    "Classify the text into neutral, negative or positive.\n",
    "<</SYS>>\n",
    "\n",
    "I like this.[/INST]\n",
    "positive\n",
    "[INST] I hate this [/INST]\n",
    "negative\n",
    "[INST] this is ok [/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac91a7-3ce7-445d-8c60-afdb8de823d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "413650a5-3a7d-49a5-95a5-17f82c760c5c",
   "metadata": {},
   "source": [
    "## Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092f7853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] True or False. The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82. [/INST]\n",
      "\n",
      "False.\n",
      "\n",
      "The sum of the odd numbers in the group is 15 + 32 + 5 = 52, which is an odd number.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST] True or False. The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82. [/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ecce6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. [/INST]\n",
      "A: Odd numbers in the group are: 9, 15, 1. Sum of them is 25. 25 is odd. The answer is False.\n",
      "[INST] The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82. [/INST]\n",
      "A: Odd numbers in the group are: 15, 5, 13. Sum of them is 33. 33 is odd. The answer is False.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST] The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. [/INST]\n",
    "A: Odd numbers in the group are: 9, 15, 1. Sum of them is 25. 25 is odd. The answer is False.\n",
    "[INST] The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82. [/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0200ce0-587d-41f2-a6e1-590dd69ff5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5c841eb-bf3f-4344-a613-de80c1894eb0",
   "metadata": {},
   "source": [
    " Side note: LLMs should ideally not be used for numbers/calculations. Agent based system can be used where LLM has access to an agent (like calculator) to perform calculations.\n",
    "\n",
    " Also larger models can be used to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c528645-866c-4d25-96f5-08ee18a10c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] True or False?\n",
      "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82. \n",
      "Let's think step by step. [/INST]\n",
      "\n",
      "True.\n",
      "\n",
      "To find the sum of the odd numbers in the group, we can add up the individual odd numbers:\n",
      "\n",
      "15 + 32 + 5 + 13 = 63\n",
      "\n",
      "Since 63 is an even number, the sum of the odd numbers in the group is even.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST] True or False?\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82. \n",
    "Let's think step by step. [/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fb980-7bb7-485c-93af-945ea15aaeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab2fd575-c319-4ee8-a811-47330c7d73f4",
   "metadata": {},
   "source": [
    "## Prompting for Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50f0f000-e8fd-466f-808d-cb8a18312523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] <<SYS>>\n",
      "Respond only by quoting from the TV series Friends\n",
      "<</SYS>>\n",
      "\n",
      "Hi[/INST]\n",
      "\"How you doin'?\"\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST] <<SYS>>\n",
    "Respond only by quoting from the TV series Friends\n",
    "<</SYS>>\n",
    "\n",
    "Hi[/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e838506-01b7-43e4-bac4-a369a6384493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] <<SYS>>\n",
      "Respond only by quoting from the TV series Friends\n",
      "<</SYS>>\n",
      "\n",
      "Hi[/INST]\n",
      "\"How you doin'?\"\n",
      "[INST] whats the capital of India?[/INST]\n",
      "\"Oh, India? *thinks* Let me see... *pauses* Oh, I know this one! *smiling* The capital of India is... *drumroll* Delhi! *wink*\"\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST] <<SYS>>\n",
    "Respond only by quoting from the TV series Friends\n",
    "<</SYS>>\n",
    "\n",
    "Hi[/INST]\n",
    "\"How you doin'?\"\n",
    "[INST] whats the capital of India?[/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4299c1-3612-4b7a-bf9e-c159fc4b625d",
   "metadata": {},
   "source": [
    "#### Another example for Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e521c4-084b-41c3-bd00-b57854720477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] <<SYS>>\n",
      "Respond only by using emojis\n",
      "<</SYS>>\n",
      "\n",
      "Hi[/INST]\n",
      "ðŸ‘‹\n",
      "[INST] whats the capital of India?[/INST]\n",
      "ðŸ‡®ðŸ‡³\n",
      "[INST] show me some dance move [/INST]\n",
      "ðŸ’ƒðŸ•º\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST] <<SYS>>\n",
    "Respond only by using emojis\n",
    "<</SYS>>\n",
    "\n",
    "Hi[/INST]\n",
    "ðŸ‘‹\n",
    "[INST] whats the capital of India?[/INST]\n",
    "ðŸ‡®ðŸ‡³\n",
    "[INST] show me some dance move [/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b763a83-955b-4586-a36d-a9e393395eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] \n",
      "Hi, my name is Yash and I am 27[/INST]\n",
      "Hello Yash\n",
      "[INST] whats the capital of India?[/INST]\n",
      "Delhi\n",
      "[INST] whats my name? [/INST]\n",
      "Your name is Yash.\n",
      "[INST] what is my age?[/INST]\n",
      "You are 27 years old.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "[INST] \n",
    "Hi, my name is Yash and I am 27[/INST]\n",
    "Hello Yash\n",
    "[INST] whats the capital of India?[/INST]\n",
    "Delhi\n",
    "[INST] whats my name? [/INST]\n",
    "Your name is Yash.\n",
    "[INST] what is my age?[/INST]\n",
    "'''\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea9f6b-a2a1-41b5-87fb-425a995f0b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
