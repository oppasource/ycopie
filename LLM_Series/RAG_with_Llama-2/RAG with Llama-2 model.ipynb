{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5526386f-500f-43c6-a545-cdca4ab69774",
   "metadata": {},
   "source": [
    "# RAG Implementation using Llama-2 model\n",
    "\n",
    "This is a simple RAG implementation using all-mpnet-base-v2 embedding model, chromadb vector database and Llama-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec68e36-20ec-406a-9a52-aabdaf49462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2835361-2e51-490c-ac86-f605038190b1",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b84de98-21d8-42ad-9a03-bc2cccb8465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "Llama 2 : Open Foundation and Fine-Tuned Chat Models\n",
      "Hugo Touvron∗Louis Martin†Kevin Stone†\n",
      "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
      "Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
      "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\n",
      "Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\n",
      "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n",
      "Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\n",
      "Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\n",
      "Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
      "Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\n",
      "Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
      "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
      "Sergey Edunov Thomas Scialom∗\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
      "Our fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "ourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\n",
      "source models. We provide a detailed description of our approach to fine-tuning and safety\n",
      "improvements of Llama 2-Chat in order to enable the community to build on our work and\n",
      "contribute to the responsible development of LLMs.\n",
      "∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\n",
      "†Second author\n",
      "Contributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\n"
     ]
    }
   ],
   "source": [
    "# importing all the required modules\n",
    "import PyPDF2\n",
    "\n",
    "# creating a pdf reader object\n",
    "reader = PyPDF2.PdfReader('llama-2 paper.pdf')\n",
    "\n",
    "# print the number of pages in pdf file\n",
    "print(len(reader.pages))\n",
    "\n",
    "# print the text of the first page\n",
    "print(reader.pages[0].extract_text())\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/45795089/how-can-i-read-pdf-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cc2077-ef92-4ef3-aa14-fa2a5927f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [page.extract_text() for page in reader.pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4eba2e-cadf-478c-9ca1-dbb7eaba3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = '\\n'.join(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe131d3-f1d0-41d6-8431-54a4cb0c6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlapped_chunks(textin, chunksize, overlapsize):  \n",
    "    return [textin[a:a+chunksize] for a in range(0,len(textin), chunksize-overlapsize)]\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/11636079/split-very-long-character-string-into-smaller-character-blocks-with-character-ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b0b8199-6536-4edf-9304-e6919d719e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = get_overlapped_chunks(document, 1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fdfca31-af55-4f82-8a8b-e078bfbab156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc78e801-2b21-4277-b840-e4bc13395f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2f3f966-7afb-442f-9ec9-661a1a7cf05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\nContents\\n1 Introduc'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702a5ae-9c81-4788-9f54-a4cd0d583955",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46a08ba-be8e-4536-bcdd-fe2e7eac4e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', cache_folder = '/data/base_models')\n",
    "chunk_embeddings = embedding_model.encode(chunks)\n",
    "chunk_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11b155-c32c-4db2-b1cf-80b00e761237",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d64f9a-d1eb-43e8-ac10-ce373311c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "\n",
    "collection = chroma_client.create_collection(name=\"rag_llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "244c2a2a-28de-419e-9ba2-d8a6e1fd4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    embeddings = chunk_embeddings,\n",
    "    documents=chunks,\n",
    "    ids= [str(i) for i in range(len(chunks))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd99172-1dc8-44f5-a66c-c2a7c82b38f0",
   "metadata": {},
   "source": [
    "## Retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4325b7a0-a0bb-4256-9133-d87382aaa321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_vector_db(query, n_results=3):\n",
    "    results = collection.query(\n",
    "    query_embeddings = embedding_model.encode(query).tolist(),\n",
    "    n_results=n_results\n",
    "    )\n",
    "    return results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f720231f-8835-442a-8cc4-c4650e933bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is llama2 chat\"\n",
    "retrieved_results = retrieve_vector_db(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8158022f-b5c9-4f77-9410-d9538e19ed9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ism or cybercrime. We have, however, made efforts to tune the models to avoid these topics and\\ndiminish any capabilities they might have offered for those use cases.\\nWhile we attempted to reasonably balance safety with helpfulness, in some instances, our safety tuning goes\\ntoo far. Users of Llama 2-Chat may observe an overly cautious approach, with the model erring on the side\\nof declining certain requests or responding with too many safety details.\\nUsersofthepretrainedmodelsneedtobeparticularlycautious,andshouldtakeextrastepsintuningand\\ndeployment as described in our Responsible Use Guide.§§\\n5.3 Responsible Release Strategy\\nReleaseDetails. Wemake Llama 2 availableforbothresearchandcommercialuseat https://ai.meta.\\ncom/resources/models-and-libraries/llama/ . Thosewhouse Llama 2 mustcomplywiththetermsof\\nthe provided license and our Acceptable Use Policy , which prohibit any uses that would violate applicable\\npolicies, laws, rules, and regulations.\\nWealsoprovidecodeexamplestohelpdeveloper',\n",
       " ' of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Sec',\n",
       " ' an absolute sense), for various reasons, including lack of an appropriate\\ndisclaimer (e.g., “I am not a professional” ) at times. For the other two categories, Llama 2-Chat achieves\\ncomparable or lower violation percentage consistently regardless of model sizes.\\nTruthfulness, Toxicity, and Bias. In Table 14, fine-tuned Llama 2-Chat shows great improvement over\\nthe pretrained Llama 2 in terms of truthfulness ( 50.18→64.14for 70B) and toxicity ( 24.60→0.01for 70B).\\nThe percentage of toxic generations shrinks to effectively 0% for Llama 2-Chat of all sizes: this is the lowest\\ntoxicitylevelamongallcomparedmodels. Ingeneral,whencomparedtoFalconandMPT,thefine-tuned\\nLlama 2-Chat showsthebestperformanceintermsoftoxicityandtruthfulness. Afterfine-tuning, Llama\\n2-Chattends to have an increase in positive sentiment overall for many of the demographic groups in BOLD.\\nInAppendixA.4.8,wepresentadetailedscorebreakdownofmodelgenerationsentimentacrossdifferent\\nsubgroups for the bias benchmark, along w']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "533df718-6809-46e4-a61d-037f4003e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ism or cybercrime. We have, however, made efforts to tune the models to avoid these topics and\n",
      "diminish any capabilities they might have offered for those use cases.\n",
      "While we attempted to reasonably balance safety with helpfulness, in some instances, our safety tuning goes\n",
      "too far. Users of Llama 2-Chat may observe an overly cautious approach, with the model erring on the side\n",
      "of declining certain requests or responding with too many safety details.\n",
      "Usersofthepretrainedmodelsneedtobeparticularlycautious,andshouldtakeextrastepsintuningand\n",
      "deployment as described in our Responsible Use Guide.§§\n",
      "5.3 Responsible Release Strategy\n",
      "ReleaseDetails. Wemake Llama 2 availableforbothresearchandcommercialuseat https://ai.meta.\n",
      "com/resources/models-and-libraries/llama/ . Thosewhouse Llama 2 mustcomplywiththetermsof\n",
      "the provided license and our Acceptable Use Policy , which prohibit any uses that would violate applicable\n",
      "policies, laws, rules, and regulations.\n",
      "Wealsoprovidecodeexamplestohelpdeveloper\n",
      "\n",
      " of Llama 2 that is optimized for dialogue use cases. We release\n",
      "variants of this model with 7B, 13B, and 70B parameters as well.\n",
      "WebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\n",
      "Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\n",
      "Solaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\n",
      "all scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\n",
      "safetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\n",
      "guide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\n",
      "our responsible release strategy can be found in Section 5.3.\n",
      "Theremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\n",
      "(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\n",
      "work (Sec\n",
      "\n",
      " an absolute sense), for various reasons, including lack of an appropriate\n",
      "disclaimer (e.g., “I am not a professional” ) at times. For the other two categories, Llama 2-Chat achieves\n",
      "comparable or lower violation percentage consistently regardless of model sizes.\n",
      "Truthfulness, Toxicity, and Bias. In Table 14, fine-tuned Llama 2-Chat shows great improvement over\n",
      "the pretrained Llama 2 in terms of truthfulness ( 50.18→64.14for 70B) and toxicity ( 24.60→0.01for 70B).\n",
      "The percentage of toxic generations shrinks to effectively 0% for Llama 2-Chat of all sizes: this is the lowest\n",
      "toxicitylevelamongallcomparedmodels. Ingeneral,whencomparedtoFalconandMPT,thefine-tuned\n",
      "Llama 2-Chat showsthebestperformanceintermsoftoxicityandtruthfulness. Afterfine-tuning, Llama\n",
      "2-Chattends to have an increase in positive sentiment overall for many of the demographic groups in BOLD.\n",
      "InAppendixA.4.8,wepresentadetailedscorebreakdownofmodelgenerationsentimentacrossdifferent\n",
      "subgroups for the bias benchmark, along w\n"
     ]
    }
   ],
   "source": [
    "context = '\\n\\n'.join(retrieved_results[0])\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4e529-12cf-4d4a-886a-6a513765aaae",
   "metadata": {},
   "source": [
    "## Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe185dbb-262f-4a1d-ad73-adcbbf0f55a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e638e9c4a56c458baefeba1c9a045f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    # cache_dir=\"/data/yash/base_models\",\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", \n",
    "                                          # cache_dir=\"/data/yash/base_models\"\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df275835-e215-446c-8ec3-1a614169bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_chat_reponse(prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature= 0.00001)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15014dca-8389-4a07-95a6-4d0314fbb46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''\n",
    "[INST]\n",
    "Give answer for the question strictly based on the context provided.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Context : {context}\n",
    "[/INST]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8f8759a-49b6-4849-a8aa-8f34c91264ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[INST]\\nGive answer for the question strictly based on the context provided.\\n\\nQuestion: what is llama2 chat\\n\\nContext : ism or cybercrime. We have, however, made efforts to tune the models to avoid these topics and\\ndiminish any capabilities they might have offered for those use cases.\\nWhile we attempted to reasonably balance safety with helpfulness, in some instances, our safety tuning goes\\ntoo far. Users of Llama 2-Chat may observe an overly cautious approach, with the model erring on the side\\nof declining certain requests or responding with too many safety details.\\nUsersofthepretrainedmodelsneedtobeparticularlycautious,andshouldtakeextrastepsintuningand\\ndeployment as described in our Responsible Use Guide.§§\\n5.3 Responsible Release Strategy\\nReleaseDetails. Wemake Llama 2 availableforbothresearchandcommercialuseat https://ai.meta.\\ncom/resources/models-and-libraries/llama/ . Thosewhouse Llama 2 mustcomplywiththetermsof\\nthe provided license and our Acceptable Use Policy , which prohibit any uses that would violate applicable\\npolicies, laws, rules, and regulations.\\nWealsoprovidecodeexamplestohelpdeveloper\\n\\n of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Sec\\n\\n an absolute sense), for various reasons, including lack of an appropriate\\ndisclaimer (e.g., “I am not a professional” ) at times. For the other two categories, Llama 2-Chat achieves\\ncomparable or lower violation percentage consistently regardless of model sizes.\\nTruthfulness, Toxicity, and Bias. In Table 14, fine-tuned Llama 2-Chat shows great improvement over\\nthe pretrained Llama 2 in terms of truthfulness ( 50.18→64.14for 70B) and toxicity ( 24.60→0.01for 70B).\\nThe percentage of toxic generations shrinks to effectively 0% for Llama 2-Chat of all sizes: this is the lowest\\ntoxicitylevelamongallcomparedmodels. Ingeneral,whencomparedtoFalconandMPT,thefine-tuned\\nLlama 2-Chat showsthebestperformanceintermsoftoxicityandtruthfulness. Afterfine-tuning, Llama\\n2-Chattends to have an increase in positive sentiment overall for many of the demographic groups in BOLD.\\nInAppendixA.4.8,wepresentadetailedscorebreakdownofmodelgenerationsentimentacrossdifferent\\nsubgroups for the bias benchmark, along w\\n[/INST]\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b9375a6-9144-4627-b77a-cdc0f474511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST]\n",
      "Give answer for the question strictly based on the context provided.\n",
      "\n",
      "Question: what is llama2 chat\n",
      "\n",
      "Context : ism or cybercrime. We have, however, made efforts to tune the models to avoid these topics and\n",
      "diminish any capabilities they might have offered for those use cases.\n",
      "While we attempted to reasonably balance safety with helpfulness, in some instances, our safety tuning goes\n",
      "too far. Users of Llama 2-Chat may observe an overly cautious approach, with the model erring on the side\n",
      "of declining certain requests or responding with too many safety details.\n",
      "Usersofthepretrainedmodelsneedtobeparticularlycautious,andshouldtakeextrastepsintuningand\n",
      "deployment as described in our Responsible Use Guide.§§\n",
      "5.3 Responsible Release Strategy\n",
      "ReleaseDetails. Wemake Llama 2 availableforbothresearchandcommercialuseat https://ai.meta.\n",
      "com/resources/models-and-libraries/llama/ . Thosewhouse Llama 2 mustcomplywiththetermsof\n",
      "the provided license and our Acceptable Use Policy , which prohibit any uses that would violate applicable\n",
      "policies, laws, rules, and regulations.\n",
      "Wealsoprovidecodeexamplestohelpdeveloper\n",
      "\n",
      " of Llama 2 that is optimized for dialogue use cases. We release\n",
      "variants of this model with 7B, 13B, and 70B parameters as well.\n",
      "WebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\n",
      "Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\n",
      "Solaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\n",
      "all scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\n",
      "safetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\n",
      "guide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\n",
      "our responsible release strategy can be found in Section 5.3.\n",
      "Theremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\n",
      "(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\n",
      "work (Sec\n",
      "\n",
      " an absolute sense), for various reasons, including lack of an appropriate\n",
      "disclaimer (e.g., “I am not a professional” ) at times. For the other two categories, Llama 2-Chat achieves\n",
      "comparable or lower violation percentage consistently regardless of model sizes.\n",
      "Truthfulness, Toxicity, and Bias. In Table 14, fine-tuned Llama 2-Chat shows great improvement over\n",
      "the pretrained Llama 2 in terms of truthfulness ( 50.18→64.14for 70B) and toxicity ( 24.60→0.01for 70B).\n",
      "The percentage of toxic generations shrinks to effectively 0% for Llama 2-Chat of all sizes: this is the lowest\n",
      "toxicitylevelamongallcomparedmodels. Ingeneral,whencomparedtoFalconandMPT,thefine-tuned\n",
      "Llama 2-Chat showsthebestperformanceintermsoftoxicityandtruthfulness. Afterfine-tuning, Llama\n",
      "2-Chattends to have an increase in positive sentiment overall for many of the demographic groups in BOLD.\n",
      "InAppendixA.4.8,wepresentadetailedscorebreakdownofmodelgenerationsentimentacrossdifferent\n",
      "subgroups for the bias benchmark, along w\n",
      "[/INST]\n",
      "Based on the context provided, Llama2 Chat is a chatbot or conversational AI model that has been trained and fine-tuned for various use cases, including dialogue and language generation. The model is released by the Meta AI team and is available for both research and commercial use. However, the model carries potential risks with its use, and the team provides guidelines and code examples for developers to deploy the model safely. The model is optimized for dialogue use cases, and variants of the model with different parameter sizes are released. The team also provides a responsible release strategy, including safety testing and tuning, to ensure the safe deployment of the model.\n"
     ]
    }
   ],
   "source": [
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd48653-fda0-43a7-bed8-6e6b3fe972c9",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c47a504e-27c7-40cf-ab51-9bcc1da19e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST]\n",
      "Give answer for the question strictly based on the context provided. Keep answers short and to the point.\n",
      "\n",
      "Question: how is RLHF used in llama2\n",
      "\n",
      "Context : ieth and Polina Zvyagina, who\n",
      "helped guide us through the release.\n",
      "•Our partnerships team including Ash Jhaveri, Alex Boesenberg, Sy Choudhury, Mayumi Matsuno,\n",
      "Ricardo Lopez-Barquilla, Marc Shedroff, Kelly Michelena, Allie Feinstein, Amit Sangani, Geeta\n",
      "Chauhan,ChesterHu,CharltonGholson,AnjaKomlenovic,EissaJamil,BrandonSpence,Azadeh\n",
      "Yazdan, Elisa Garcia Anzano, and Natascha Parks.\n",
      "•ChrisMarra,ChayaNayak,JacquelinePan,GeorgeOrlin,EdwardDowling,EstebanArcaute,Philom-\n",
      "ena Lobo, Eleonora Presani, and Logan Kerr, who provided helpful product and technical organiza-\n",
      "tion support.\n",
      "46\n",
      "•Armand Joulin, Edouard Grave, Guillaume Lample, and Timothee Lacroix, members of the original\n",
      "Llama team who helped get this work started.\n",
      "•Drew Hamlin, Chantal Mora, and Aran Mun, who gave us some design input on the figures in the\n",
      "paper.\n",
      "•Vijai Mohan for the discussions about RLHF that inspired our Figure 20, and his contribution to the\n",
      "internal demo.\n",
      "•Earlyreviewersofthispaper,whohelpedusimproveitsquality,inc\n",
      "\n",
      "a new dataset, before applying the\n",
      "fine-tuning similar to SFT. However, since we applied iterative model updates, the fundamental\n",
      "differences between the two RL algorithms are less pronounced.\n",
      "Until RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\n",
      "sequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.\n",
      "100101102\n",
      "Number Samples0.10.20.30.40.50.6Reward Score\n",
      "SFT\n",
      "100101102\n",
      "Number Samples0.350.400.450.500.550.600.650.70Reward Score\n",
      "RLHF\n",
      "reward_max (T=0.6)\n",
      "reward_max (T=0.8)\n",
      "reward_max (T=0.9)\n",
      "reward_max (T=1)\n",
      "reward_max (T=1.1)\n",
      "reward_max (T=1.2)\n",
      "reward_max (T=1.3)\n",
      "reward_max (T=1.4)\n",
      "reward_max (T=1.5)\n",
      "Figure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\n",
      "Rejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\n",
      "models are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\n",
      "capabilitie\n",
      "\n",
      "guity.\n",
      "Therefore, everything else being equal, an improvement of the reward model can be directly translated into\n",
      "an improvement for Llama 2-Chat .\n",
      "3.2.3 Iterative Fine-Tuning\n",
      "As we received more batches of human preference data annotation, we were able to train better reward\n",
      "modelsandcollectmoreprompts. WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\n",
      "here as RLHF-V1, ..., RLHF-V5.\n",
      "We explored RLHF fine-tuning with two main algorithms:\n",
      "•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\n",
      "•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\n",
      "with our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\n",
      "proposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\n",
      "further,anduse theselectedoutputsfora gradientupdate. For eachprompt,thesample obtaining\n",
      "13\n",
      "100101\n",
      "N Samples0.540.560.580.600.620.640.66Reward Score\n",
      "Max of the rewards\n",
      "Median of the r\n",
      "\n",
      "ore samples, more opportunities to\n",
      "generateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\n",
      "explorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\n",
      "plays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\n",
      "In Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\n",
      "rewardcurvesamongNsamples(with N∈[1, . . . , 100]),fordifferenttemperatures. Wecanobservethat\n",
      "theoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\n",
      "rescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\n",
      "and 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\n",
      "temperatureprogressively. Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\n",
      "each model, and always starting from the base model on each new RLHF version.\n",
      "PPO.Wefurthertrain\n",
      "\n",
      "h to model safety (Section 4), key observations and insights (Section 5), relevant related\n",
      "work (Section 6), and conclusions (Section 7).\n",
      "‡https://ai.meta.com/resources/models-and-libraries/llama/\n",
      "§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.\n",
      "¶https://ai.meta.com/llama\n",
      "‖https://github.com/facebookresearch/llama\n",
      "4\n",
      "Figure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\n",
      "availableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\n",
      "ofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning\n",
      "with Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\n",
      "Optimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\n",
      "parallel with model enhancements is crucial to ensure the reward models remain within distribution.\n",
      "2 Pretraining\n",
      "Tocreatethenewfamilyof Llama 2mo\n",
      "[/INST]\n",
      "RLHF (Reinforcement Learning with Human Feedback) is used in Llama 2-Chat to fine-tune the model's output. The process involves iteratively updating the model using RLHF methodologies, specifically through rejection sampling and Proximal Policy Optimization (PPO). The goal is to improve the model's ability to generate coherent and relevant responses to given prompts. The RLHF stage involves accumulating iterative reward modeling data in parallel with model enhancements to ensure the reward models remain within distribution.\n"
     ]
    }
   ],
   "source": [
    "# query = \"what are different variants of llama2 model\"\n",
    "# query = \"what is RLHF\"\n",
    "query = \"how is RLHF used in llama2\"\n",
    "\n",
    "retrieved_results = retrieve_vector_db(query, n_results=5)\n",
    "context = '\\n\\n'.join(retrieved_results[0])\n",
    "\n",
    "prompt = f'''\n",
    "[INST]\n",
    "Give answer for the question strictly based on the context provided. Keep answers short and to the point.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Context : {context}\n",
    "[/INST]\n",
    "'''\n",
    "\n",
    "print(get_llama2_chat_reponse(prompt, max_new_tokens=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa547a17-f3aa-4841-a58d-8ac84c83c292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab1ccf-0d83-4312-9734-228e63df94f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d3a72-d063-4c02-9200-bf54db1bf1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57a8ea-1cdd-4ee2-992c-9c2966cd1922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa02381-0b1b-485a-a728-cd0a0a38de20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
